{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef8ae6-a054-4a64-9c97-4b373bb8130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "\"Libraries to help with jupyter notebook usage\"\n",
    "# Increases jupyter notebook display width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "# Helps display images in notebook\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1982b9d",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "Import files containing information regarding tracks from over 10,000 playlists in terms of audio featuers and various details such as global popularity and release date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_df = []\n",
    "track_details_df = []\n",
    "\n",
    "for i in range(10):\n",
    "    audio_features_file_path = f'../data/processed_data/audio_features/audio_features-{i*1000}-{(i+1)*1000 - 1}.csv'\n",
    "    df = pd.read_csv(audio_features_file_path)\n",
    "    audio_features_df.append(df)\n",
    "    \n",
    "    track_details_file_path = f'../data/processed_data/playlist_details/details-{i*1000}-{(i+1)*1000 - 1}.csv'\n",
    "    df = pd.read_csv(track_details_file_path)\n",
    "    track_details_df.append(df)\n",
    "\n",
    "audio_features_df = pd.concat(audio_features_df, ignore_index=True)\n",
    "track_details_df = pd.concat(track_details_df, ignore_index=True)\n",
    "\n",
    "original_track_details_df = track_details_df.copy()\n",
    "original_audio_features_df = audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f6d68",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing\n",
    "1. Remove irrelevant columns such as key and duration\n",
    "2. Remove outliers for each audio features in `audio_features_df`\n",
    "3. Perform One-Hot-Encoding (OHE) for `track_popularity` and `release_date` in `track_details_df`\n",
    "4. Combining `audio_features_df` and `track_details_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_df = original_audio_features_df.drop(columns=['key', 'duration_ms', 'instrumentalness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac94f4",
   "metadata": {},
   "source": [
    "### 2.2 Removing outliers from audio features\n",
    "Despite the official Spotify API Documentation mentioning that most audio features are within the range of 0 to 1, a simple `track_details_df.describe()` shows its definitely not the case. To better visualize each audio feature's distribution, let's plot them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea94352",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_audio_features_df = audio_features_df.copy()\n",
    "\n",
    "num_bins = 250\n",
    "\n",
    "audio_features_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "graph_height = 4\n",
    "graph_width = 4\n",
    "graph_count = len(audio_features_list)\n",
    "\n",
    "fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "fig.suptitle('Frequency Histograms of Audio Features', fontsize=16)\n",
    "\n",
    "for i, audio_feature in enumerate(audio_features_list):\n",
    "    ax = axes[i]\n",
    "    ax.hist(graph_audio_features_df[audio_feature], bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "    ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "    ax.set_xlabel(f'{audio_feature.capitalize()}')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed315ad",
   "metadata": {},
   "source": [
    "It's immediately noticeable that only audio features `Danceability`, `Energy`, and `Valence` are \"normal\" (excuse the pun). The distribution of `Loudness` is also noticeably messy due to its range of [-60, 0], let's fix that using min-max normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03034f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_loudness = 0\n",
    "min_loudness = -60\n",
    "graph_audio_features_df['normalized_loudness'] = (graph_audio_features_df['loudness'] - min_loudness) / (max_loudness - min_loudness)\n",
    "\n",
    "audio_features_list = ['loudness', 'normalized_loudness']\n",
    "\n",
    "graph_count = len(audio_features_list)\n",
    "\n",
    "fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "fig.suptitle('Frequency Histograms of Loudness Before vs After Normalization', fontsize=16)\n",
    "\n",
    "for i, audio_feature in enumerate(audio_features_list):\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax.hist(graph_audio_features_df[audio_feature], bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "    ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "    ax.set_xlabel(f'{audio_feature.capitalize()}')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "graph_audio_features_df['loudness'] = graph_audio_features_df['normalized_loudness']\n",
    "graph_audio_features_df = graph_audio_features_df.drop(columns=['normalized_loudness'])\n",
    "    \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f5909",
   "metadata": {},
   "source": [
    "Looks so much better. Now that we know `Loudness` is heavily left-skewed, while `Speechiness`, `Acousticness` and `Liveness` are heavily right-skewed, we can perform square-transformation and square-root-transformation to them respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_list = ['loudness','speechiness', 'acousticness', 'liveness']\n",
    "\n",
    "new_graph_audio_features_df = graph_audio_features_df.copy()\n",
    "new_graph_audio_features_df['loudness'] = graph_audio_features_df['loudness'].apply(lambda x : x**3)\n",
    "\n",
    "def normalize_using_iqr(x):\n",
    "    median = x.median()\n",
    "    iqr = x.quantile(0.75) - x.quantile(0.25)\n",
    "    return (x - median) / iqr\n",
    "\n",
    "non_zero_columns = ['speechiness', 'acousticness', 'liveness']\n",
    "for column in non_zero_columns:\n",
    "    new_graph_audio_features_df[column] = graph_audio_features_df[column].apply(lambda x : np.sqrt(x))\n",
    "\n",
    "\n",
    "graph_count = len(audio_features_list)\n",
    "\n",
    "fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "fig.suptitle('Frequency Histogram of Heavily-skewed Audio Features Before Normalizing', fontsize=16)\n",
    "\n",
    "for i, audio_feature in enumerate(audio_features_list):\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax.hist(graph_audio_features_df[audio_feature], bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "    ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "fig.suptitle('Frequency Histogram of Heavily-skewed Audio Features After Normalizing', fontsize=16)\n",
    "\n",
    "for i, audio_feature in enumerate(audio_features_list):\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax.hist(new_graph_audio_features_df[audio_feature], bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "    ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c03eb",
   "metadata": {},
   "source": [
    "Although several audio features are yet to be close to normal, it is still way better than where we started from. Here's the final frequency histograms for every audio feature after various normalization techniques have been applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence']\n",
    "graph_count = len(audio_features_list)\n",
    "\n",
    "fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "fig.suptitle('Frequency Histograms of Audio Features', fontsize=16)\n",
    "\n",
    "for i, audio_feature in enumerate(audio_features_list):\n",
    "    ax = axes[i]\n",
    "    ax.hist(new_graph_audio_features_df[audio_feature], bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "    ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "    ax.set_xlabel(f'{audio_feature.capitalize()}')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "audio_features_df = new_graph_audio_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b1c57",
   "metadata": {},
   "source": [
    "### 2.3 One-Hot-Encoding (OHE) for `track_popularity` and `release_date` in `track_details_df`\n",
    "One-Hot Encoding (OHE) is used to convert categorical variables into a binary format, where each category is represented by a separate binary feature, making the data suitable for machine learning algorithms that require numerical inputs. Here's how we will be performing OHE:\n",
    "- OHE for `track_popularity` can be done by grouping them into buckets of their nearest 10s\n",
    "- OHE for `release_date` can be done by grouping them into the year released "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_details_df['release_date'] = original_track_details_df['release_date'].apply(lambda date_str: date_str.split('-')[0] if isinstance(date_str, str) and '-' in date_str else date_str)\n",
    "\n",
    "track_details_df['track_popularity'] = original_track_details_df['track_popularity'].apply(lambda popularity: (int(popularity // 10) * 10) if not pd.isna(popularity) else popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaae6d0",
   "metadata": {},
   "source": [
    "### 2.4 Combining `audio_features_df` and `track_details_df`\n",
    "\n",
    "Due to some issues with spotify's song database, the audio_features for all songs still remain in the DB (presumably for song analysis purpose), but the track details (allbum, date of release, artist) have been removed. \n",
    "\n",
    "This caused quite a headache and took quite a long time to realize the issue, but alast it has been fixed, the rows with such missing data has been labelled as NA during the data retrieval process, for simple data pre-processing.\n",
    "\n",
    "The `merged_df` now contains information from `audio_features_df` as well as `track_details_df`, joined on the track id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = audio_features_df.merge(track_details_df, on='id', how='inner')\n",
    "\n",
    "tracks_with_missing_details = merged_df.loc[merged_df['track_uri'].isna(), 'id']\n",
    "\n",
    "merged_df = merged_df.drop(index=merged_df[merged_df['id'].isin(tracks_with_missing_details)].index)\n",
    "\n",
    "merged_df['tempo'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4767a",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "## Scatter Plot \n",
    "Allows better visualization of how one audio feature tends to affect the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723e683-ef31-4008-b4f3-7c82866bc85c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "audio_features = filtered_df.columns[1:]\n",
    "\n",
    "num_rows = 1\n",
    "num_cols = len(audio_features)\n",
    "\n",
    "subplot_size = 5\n",
    "fig_row_size = subplot_size * num_cols\n",
    "fig_col_size = subplot_size\n",
    "\n",
    "audio_features_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "for af in audio_features_list:\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(fig_row_size, fig_col_size))\n",
    "    \n",
    "    for i, feature in enumerate(audio_features):\n",
    "        axs[i].hexbin(x=filtered_df[af], y=filtered_df[feature], alpha=1, gridsize=25, cmap='terrain')\n",
    "        \n",
    "        axs[i].set_xlabel(af)\n",
    "        axs[i].set_ylabel(feature)\n",
    "        \n",
    "        # Adding linear regression line\n",
    "        slope, intercept = np.polyfit(filtered_df[af], filtered_df[feature], 1)\n",
    "        x_values = [filtered_df[af].min(), filtered_df[af].max()]\n",
    "        y_values = [slope * x + intercept for x in x_values]\n",
    "        axs[i].plot(x_values, y_values, color='red', linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../resources/audio_feature_plots/plot_{af}.png\", format=\"png\", dpi=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605af4f",
   "metadata": {},
   "source": [
    "## Correlation Matrix\n",
    "Overview of the correlation between audio features (note: correlation need not necessarily imply causation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adda922-c455-4d97-8686-bfb2625e884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already calculated the correlation_matrix\n",
    "correlation_matrix = filtered_df[audio_features_list].corr()\n",
    "\n",
    "# Create a mask to hide the lower triangle (including the diagonal)\n",
    "mask = np.tril(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Plotting the correlation matrix as a heatmap, showing only the values in the upper triangle\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", center=0, mask=~mask)\n",
    "plt.title(\"Correlation Matrix of Audio Features\")\n",
    "plt.savefig(f\"../resources/audio_feature_plots/correlation.png\", format=\"png\", dpi=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8806ecc",
   "metadata": {},
   "source": [
    "## Genre Clustering\n",
    "Clusters genres obtained from Spotify API using kmeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import global_genres as definitions\n",
    "\n",
    "# Convert the preprocessed definitions to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(definitions)\n",
    "\n",
    "# Use K-means clustering to group similar definitions\n",
    "num_clusters = 15\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Concatenate definitions for each cluster without the cluster labels\n",
    "clusters = {}\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    # Remove the [Cluster X] [X] annotations from the definitions\n",
    "    clean_definition = ' '.join([word for word in definitions[i].split() if not word.startswith('[')])\n",
    "    # Remove all numbers from the clean_definition using regex\n",
    "    clean_definition = re.sub(r'\\d+', '', clean_definition).replace(']', '')\n",
    "    clusters[label].append(clean_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d479589",
   "metadata": {},
   "source": [
    "### Cluster Based Word Cloud\n",
    "Clustering genres based on definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0399c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate word clouds for each cluster\n",
    "for label, cluster_definitions in clusters.items():\n",
    "    all_definitions = ' '.join(cluster_definitions)\n",
    "    word_list = all_definitions.split()\n",
    "    # covert to set to remove duplicates\n",
    "    unique_words = list(set(word_list))  \n",
    "    unique_definitions = ' '.join(unique_words)\n",
    "\n",
    "    \n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(unique_definitions)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for Cluster {label}')\n",
    "    plt.savefig(f\"../resources/wordclouds/cluster_{label}.png\", format=\"png\", dpi=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f26d1",
   "metadata": {},
   "source": [
    "### Overall Word Cloud\n",
    "Word cloud based on frequency of words in each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49be1cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate word clouds for each cluster and get word frequencies\n",
    "word_frequencies = {}\n",
    "for label, cluster_definitions in clusters.items():\n",
    "    all_definitions = ' '.join(cluster_definitions)\n",
    "    word_list = all_definitions.split()\n",
    "    for word in word_list:\n",
    "        if word in word_frequencies:\n",
    "            word_frequencies[word] += 1\n",
    "        else:\n",
    "            word_frequencies[word] = 1\n",
    "\n",
    "# Generate the large word cloud with overlapping clusters\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white')\n",
    "wordcloud.generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the large word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Overall Word Cloud')\n",
    "plt.savefig(f\"../resources/wordclouds/overall.png\", format=\"png\", dpi=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38847ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cbd807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
