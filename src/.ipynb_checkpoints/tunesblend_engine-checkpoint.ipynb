{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ef8ae6-a054-4a64-9c97-4b373bb8130f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import nltk\n",
    "# from wordcloud import WordCloud\n",
    "# import re\n",
    "\n",
    "\"Libraries to help with jupyter notebook usage\"\n",
    "# Increases jupyter notebook display width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import Image # Helps display images in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b348ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Import python util functions\"\n",
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to the Python path\n",
    "\n",
    "# Now you can import the util functions\n",
    "from jupyternotebook_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1982b9d",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "Import files containing information regarding tracks from over 6000 different genres and their audio features, roughly 50 tracks per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_by_genre_file_path = f'../../data/processed_data/genres/audio_features_by_genre.csv'\n",
    "audio_features_by_genre_df = pd.read_csv(audio_features_by_genre_file_path)\n",
    "original_audio_features_by_genre_df = audio_features_by_genre_df.copy()\n",
    "\n",
    "clustered_audio_features_by_genre_file_path = f'../../data/processed_data/genres/audio_features_by_genre.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f6d68",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing\n",
    "1. Remove irrelevant columns such as key and duration\n",
    "2. Remove outliers for each audio features in `audio_features_df`\n",
    "3. Combining `audio_features_df` and `track_details_df` for easy data manipulation\n",
    "4. Perform One-Hot-Encoding (OHE) for `track_popularity` and `release_date` in `track_details_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382570d5",
   "metadata": {},
   "source": [
    "## Utility for Pre-processing\n",
    "Declaration of constants and functions to be used for data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc264b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_graph_audio_features_df = audio_features_by_genre_df.copy()\n",
    "after_graph_audio_features_df = audio_features_by_genre_df.copy()\n",
    "\n",
    "num_bins = 250\n",
    "\n",
    "graph_height = 4\n",
    "graph_width = 4\n",
    "\n",
    "audio_features_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence']\n",
    "\n",
    "def plot_graph(plot_title, graph_height, graph_width, graph_features_list = audio_features_list, graph_df = before_graph_audio_features_df):\n",
    "    graph_height = graph_height\n",
    "    graph_width = graph_width\n",
    "    graph_count = len(graph_features_list)\n",
    "\n",
    "    fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "    fig.suptitle(plot_title, fontsize=16)\n",
    "    \n",
    "    for i, audio_feature in enumerate(graph_features_list, start = 0):\n",
    "        ax = axes[i]\n",
    "        ax.hist(graph_df[audio_feature], bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "        ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "        ax.set_xlabel(f'{audio_feature.capitalize()}')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb45723",
   "metadata": {},
   "source": [
    "### 2.1 Removing Irrelevant Columns\n",
    "Columns such as `key` and `duration` do not provide useful insights to the analysis, hence they are removed.\n",
    "\n",
    "For now, `instrumentalness` seems to have a large number of null values, it will be dropped too to prevent messing up the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this still needed?\n",
    "\n",
    "audio_features_df = original_audio_features_df.drop(columns=['key', 'duration_ms', 'instrumentalness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac94f4",
   "metadata": {},
   "source": [
    "### 2.2 Removing outliers from audio features\n",
    "Despite the official Spotify API Documentation mentioning that most audio features are within the range of 0 to 1, a simple `track_details_df.describe()` shows its definitely not the case. To better visualize each audio feature's distribution, let's plot them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea94352",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_title = 'Frequency Histograms of Audio Features'\n",
    "plot_graph(graph_title, graph_height, graph_width, audio_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002c000",
   "metadata": {},
   "source": [
    "It's immediately noticeable that only audio features `Danceability`, `Energy`, and `Valence` are \"normal\" (excuse the pun). The distribution of `Loudness` is also noticeably messy due to its range of [-60, 0], let's fix that using min-max normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d857fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_loudness = 0\n",
    "min_loudness = -60\n",
    "after_graph_audio_features_df['loudness'] = audio_features_by_genre_df['loudness']\n",
    "after_graph_audio_features_df['normalized_loudness'] = (audio_features_by_genre_df['loudness'] - min_loudness) / (max_loudness - min_loudness)\n",
    "\n",
    "features_list = ['loudness', 'normalized_loudness']\n",
    "\n",
    "graph_title = 'Frequency Histograms of Loudness Before vs After Normalization'\n",
    "\n",
    "plot_graph(graph_title, graph_height, graph_width, features_list, after_graph_audio_features_df)\n",
    "\n",
    "before_graph_audio_features_df['loudness'] = after_graph_audio_features_df['normalized_loudness']\n",
    "after_graph_audio_features_df = before_graph_audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27f41c",
   "metadata": {},
   "source": [
    "Another quite obvious issue is with the `instrumentalness` column, which for some reason contains a large amount of null values.\n",
    "\n",
    "\n",
    "NOTE: since instrumentalness seems to have large amounts of null values, it will be dropped for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937609c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_count = 2\n",
    "\n",
    "# fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "# fig.suptitle('Frequency Histograms of Instrumentalness Before vs After Normalization', fontsize=16)\n",
    "\n",
    "# instrumentalness = audio_features_df['instrumentalness']\n",
    "# filtered_instrumentalness = instrumentalness[instrumentalness > 0].apply(lambda x : x * 10000)\n",
    "\n",
    "# columns_list = [instrumentalness, filtered_instrumentalness]\n",
    "\n",
    "# for i, columns in enumerate(columns_list):\n",
    "#     ax = axes[i]\n",
    "\n",
    "#     ax.hist(columns, bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "#     ax.set_xlabel('Instrumentalness')\n",
    "#     ax.set_ylabel('Frequency')\n",
    "    \n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cdfd3d",
   "metadata": {},
   "source": [
    "Looks so much better. Now that we know `Loudness` is heavily left-skewed, while `Speechiness`, `Acousticness` and `Liveness` are heavily right-skewed, we can perform square-transformation and square-root-transformation to them respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9707be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for left-skewed, use cube-normalization\n",
    "after_graph_audio_features_df['loudness'] = before_graph_audio_features_df['loudness'].apply(lambda x : x**3)\n",
    "\n",
    "# for right-skewed, use square-root-normalization\n",
    "non_zero_columns = ['speechiness', 'acousticness', 'liveness']\n",
    "for column in non_zero_columns:\n",
    "    after_graph_audio_features_df[column] = before_graph_audio_features_df[column].apply(lambda x : np.sqrt(x))\n",
    "\n",
    "    \n",
    "# Printing before and after graph\n",
    "features_list = ['loudness','speechiness', 'acousticness', 'liveness']\n",
    "\n",
    "graph_title_before = 'Frequency Histogram of Skewed Audio Features Before Normalizing'\n",
    "plot_graph(graph_title_before, graph_height, graph_width, features_list, before_graph_audio_features_df)\n",
    "\n",
    "    \n",
    "graph_title_after = 'Frequency Histogram of Skewed Audio Features After Normalizing'\n",
    "plot_graph(graph_title_after, graph_height, graph_width, features_list, after_graph_audio_features_df)\n",
    "\n",
    "graph_audio_features_df = after_graph_audio_features_df.copy()\n",
    "audio_features_df = after_graph_audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588921a",
   "metadata": {},
   "source": [
    "Although several audio features are yet to be close to normal, it is still way better than where we started from. Here's the final frequency histograms for every audio feature after various normalization techniques have been applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_title = 'Original Frequency Histogram of Audio Features'\n",
    "plot_graph(graph_title, graph_height, graph_width, audio_features_list, original_audio_features_by_genre_df)\n",
    "\n",
    "graph_title = 'Frequency Histograms of Audio Features'\n",
    "plot_graph(graph_title, graph_height, graph_width, audio_features_list, audio_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaae6d0",
   "metadata": {},
   "source": [
    "### 2.3 Combining audio_features_df and track_details_df\n",
    "\n",
    "Due to some issues with spotify's song database, the audio_features for all songs still remain in the DB (presumably for song analysis purpose), but the track details (allbum, date of release, artist) have been removed. \n",
    "\n",
    "This caused quite a headache and took quite a long time to realize the issue, but alast it has been fixed, the rows with such missing data has been labelled as NA during the data retrieval process, for simple data pre-processing.\n",
    "\n",
    "The `merged_df` now contains information from `audio_features_df` as well as `track_details_df`, joined on the track id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e81e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = audio_features_df.merge(track_details_df, on='id', how='inner')\n",
    "\n",
    "tracks_with_missing_details = merged_df.loc[merged_df['track_uri'].isna(), 'id']\n",
    "\n",
    "merged_df = merged_df.drop(index=merged_df[merged_df['id'].isin(tracks_with_missing_details)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888439d",
   "metadata": {},
   "source": [
    "### 2.4 One-Hot-Encoding (OHE) for `track_popularity` and `release_date` in `track_details_df`\n",
    "One-Hot Encoding (OHE) is used to convert categorical variables into a binary format, where each category is represented by a separate binary feature, making the data suitable for machine learning algorithms that require numerical inputs. Here's how we will be performing OHE:\n",
    "- OHE for `track_popularity` can be done by grouping them into buckets of their nearest 10s\n",
    "- OHE for `release_date` can be done by grouping them into the year released "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_merged_df = merged_df.copy()\n",
    "\n",
    "merged_df['release_date'] = original_merged_df['release_date'].apply(lambda date_str: date_str.split('-')[0] if isinstance(date_str, str) and '-' in date_str else date_str)\n",
    "\n",
    "merged_df['track_popularity'] = original_merged_df['track_popularity'].apply(lambda popularity: (int(popularity // 10) * 10) if not pd.isna(popularity) else popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4767a",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "## Scatter Plot \n",
    "Allows better visualization of how one audio feature tends to affect the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723e683-ef31-4008-b4f3-7c82866bc85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "num_cols = len(audio_features_list)\n",
    "\n",
    "subplot_size = 5\n",
    "fig_row_size = subplot_size * num_cols\n",
    "fig_col_size = subplot_size\n",
    "\n",
    "for af in audio_features_list:\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(fig_row_size, fig_col_size))\n",
    "    \n",
    "    for i, feature in enumerate(audio_features_list):\n",
    "        axs[i].hexbin(x=audio_features_df[af], y=audio_features_df[feature], alpha=1, gridsize=25, cmap='terrain')\n",
    "        \n",
    "        axs[i].set_xlabel(af)\n",
    "        axs[i].set_ylabel(feature)\n",
    "        \n",
    "        # Adding linear regression line\n",
    "        slope, intercept = np.polyfit(audio_features_df[af], audio_features_df[feature], 1)\n",
    "        x_values = [audio_features_df[af].min(), audio_features_df[af].max()]\n",
    "        y_values = [slope * x + intercept for x in x_values]\n",
    "        axs[i].plot(x_values, y_values, color='red', linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../../resources/audio_feature_plots/plot_{af}.png\", format=\"png\", dpi=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77ef14",
   "metadata": {},
   "source": [
    "## Genre Clustering Using KMeans Algorithm\n",
    "\n",
    "Here's an overview of the whole clustering process:\n",
    "1. Identifying the optimal value of K for the Partitioning Clustering using the Elbow Method.\n",
    "2. Run Kmeans algorithm using the optimal K value.\n",
    "3. For each cluster, re-run Elbow Method to find the optimal K value for Hierachial Subclustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8cec1d",
   "metadata": {},
   "source": [
    "### Constant Declarations for KMeans Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output # clears output for better logging\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter # used to count frequency of genres in each cluster\n",
    "\n",
    "min_clusters = 1\n",
    "max_clusters = 11\n",
    "\n",
    "# NOTE: key, and duration_ms is removed\n",
    "audio_feature_columns = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = audio_features_by_genre_df.loc[:, audio_feature_columns]\n",
    "inertia_values = []\n",
    "\n",
    "for k in range(min_clusters, max_clusters):\n",
    "    \n",
    "    status = f'Attempting Cluster Size: {k}'\n",
    "    print(status, end='\\r')  # '\\r' moves the cursor to the beginning of the same line, effectively overwriting previous line\n",
    "    \n",
    "    kmeans_main_model = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans_main_model.fit(X)\n",
    "    inertia_values.append(kmeans_main_model.inertia_)\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(min_clusters, max_clusters), inertia_values, marker='o')\n",
    "plt.title('Determining Optimal Value for K')\n",
    "plt.xlabel('Number of Clusters, K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(range(min_clusters, max_clusters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_kmeans_df = audio_features_by_genre_df.copy()\n",
    "\n",
    "X = audio_features_kmeans_df.loc[:, audio_feature_columns]\n",
    "\n",
    "num_clusters = 5\n",
    "kmeans_main_model = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans_main_model.fit(X)\n",
    "\n",
    "audio_features_kmeans_df['cluster'] = kmeans_main_model.labels_\n",
    "audio_features_kmeans_df.sort_values(by='cluster', inplace=True)\n",
    "\n",
    "selected_columns = ['genre', 'cluster', 'track_name', 'track_uri']\n",
    "selected_df = audio_features_kmeans_df[selected_columns]\n",
    "clustered_audio_features_by_genre_file_path = '../../data/processed_data/genres/clustered_audio_features_by_genre.csv'\n",
    "selected_df.to_csv(clustered_audio_features_by_genre_file_path, index=False)\n",
    "\n",
    "print(f'Sorted and selected data with cluster assignments written to {clustered_audio_features_by_genre_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed for now, to idenfity top 20 genres in each cluster\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "# # Group the DataFrame by 'cluster' and aggregate genres\n",
    "# clustered_genre_groups = selected_df.groupby('cluster')['genre'].apply(lambda x: list(x))\n",
    "\n",
    "# for cluster, genres in clustered_genre_groups.items():\n",
    "#     genre_counter = Counter(genres)\n",
    "#     most_common_genres = genre_counter.most_common(20)\n",
    "    \n",
    "#     print(f\"Cluster {cluster}:\")\n",
    "#     for genre, count in most_common_genres:\n",
    "#         print(f\"  {genre}: {count}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154b722",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_clusters = audio_features_kmeans_df['cluster'].unique()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    status = f'Finding optimal value of K for Cluster {cluster}'\n",
    "    print(status)\n",
    "    \n",
    "    # Filter data for the current cluster\n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "    X = cluster_data.loc[:, audio_feature_columns]\n",
    "\n",
    "    # Perform the elbow method to find the optimal K value\n",
    "    inertia_values = []\n",
    "    \n",
    "    for k in range(min_clusters, max_clusters):\n",
    "        status = f'Attempting Cluster Size: {k}'\n",
    "        print(status, end='\\r')\n",
    "        \n",
    "        kmeans_subcluster_model = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans_subcluster_model.fit(X)\n",
    "        inertia_values.append(kmeans_subcluster_model.inertia_)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Plot the elbow method results for each cluster on the same chart\n",
    "    plt.plot(range(min_clusters, max_clusters), inertia_values, marker='o', label=f'Cluster {cluster}')\n",
    "    plt.title('Elbow Method for Optimal K')\n",
    "    plt.xlabel('Number of Clusters (K)')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.xticks(range(min_clusters, max_clusters))\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subclusters_per_cluster = {\n",
    "    0: 6,\n",
    "    1: 6,\n",
    "    2: 7,\n",
    "    3: 7,\n",
    "    4: 6,\n",
    "}\n",
    "\n",
    "subcluster_models = {}  # Dictionary to store subcluster KMeans models\n",
    "\n",
    "# Iterate through each unique cluster label\n",
    "for cluster, num_subclusters in num_subclusters_per_cluster.items():\n",
    "    status = f'Processing Subclustering for Cluster {cluster}'\n",
    "    print(status, end='\\r')\n",
    "    \n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "\n",
    "    \"\"\"\n",
    "    - Clustering is done based on audio_features only, NOT cluster/subcluster value\n",
    "    - Each cluster is fitted to its own kmeans_model, which are stored in subcluster_models dic\n",
    "    \"\"\"\n",
    "    X_subcluster = cluster_data.loc[:, audio_feature_columns]  \n",
    "\n",
    "    # Perform subclustering for the current cluster\n",
    "    kmeans_subcluster_model = KMeans(n_clusters=num_subclusters, random_state=42)\n",
    "    kmeans_subcluster_model.fit(X_subcluster)\n",
    "    \n",
    "    # Store the subcluster KMeans model for the current cluster\n",
    "    subcluster_models[cluster] = kmeans_subcluster_model\n",
    "\n",
    "# Use the stored subcluster models to assign subcluster labels back to the original DataFrame\n",
    "for cluster, kmeans_subcluster_model in subcluster_models.items():\n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "    X_subcluster = cluster_data.loc[:, audio_feature_columns]\n",
    "    subcluster_labels = kmeans_subcluster_model.predict(X_subcluster)\n",
    "    audio_features_kmeans_df.loc[audio_features_kmeans_df['cluster'] == cluster, 'subcluster'] = subcluster_labels.astype(int)\n",
    "\n",
    "audio_features_kmeans_df.sort_values(by=['cluster', 'subcluster'], inplace=True)\n",
    "\n",
    "selected_columns = ['genre', 'cluster', 'subcluster', 'track_name', 'track_uri']\n",
    "audio_features_kmeans_df[selected_columns].to_csv(clustered_audio_features_by_genre_file_path, index=False)\n",
    "\n",
    "print(\"All subclustering processes completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d175405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out for now, no real reason to combine\n",
    "\n",
    "audio_features_kmeans_df = pd.read_csv(clustered_audio_features_by_genre_file_path)\n",
    "\n",
    "# Convert cluster and subcluster columns to integers and then combine them as strings\n",
    "audio_features_kmeans_df['genre_cluster'] = (\n",
    "    audio_features_kmeans_df['cluster'].astype(int).astype(str) +\n",
    "    ', ' +\n",
    "    audio_features_kmeans_df['subcluster'].astype(int).astype(str)\n",
    ")\n",
    "\n",
    "audio_features_kmeans_df.to_csv(clustered_audio_features_by_genre_file_path, index=False)\n",
    "\n",
    "print(\"Added 'genre_cluster' column and saved to CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98fe10",
   "metadata": {},
   "source": [
    "### Breakdown of Cluster Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69664a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_counts = audio_features_kmeans_df['cluster'].value_counts().sort_index()\n",
    "sizes = cluster_counts.values\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, autopct='', startangle=140)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.title(\"Distribution of Occurrences across Clusters\")\n",
    "plt.legend(labels=[f\"Cluster {cluster}\" for cluster in cluster_counts.index], loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "total_occurrences = len(audio_features_kmeans_df)\n",
    "\n",
    "cluster_counts = audio_features_kmeans_df['cluster'].value_counts().sort_index()\n",
    "for cluster, count in cluster_counts.items():\n",
    "    percentage = (count / total_occurrences) * 100\n",
    "    print(f\"Cluster {cluster}: {count} occurrences ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd4743",
   "metadata": {},
   "source": [
    "### Breakdown of Sub-cluster Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfff6bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subcluster_counts = audio_features_kmeans_df['genre_cluster'].value_counts().sort_index()\n",
    "total_subcluster_occurrences = len(audio_features_kmeans_df)\n",
    "subcluster_percentages = (subcluster_counts / total_subcluster_occurrences) * 100\n",
    "\n",
    "# Create a pie chart for subcluster distribution\n",
    "subcluster_labels = [f\"({subcluster})\" for subcluster in subcluster_counts.index]\n",
    "subcluster_sizes = subcluster_percentages.values\n",
    "\n",
    "plt.figure(figsize=(8, 8))  # Adjust the figure size if needed\n",
    "\n",
    "# Use the labeldistance parameter to control the label positions\n",
    "plt.pie(subcluster_sizes, labels=subcluster_labels, autopct='', startangle=140, labeldistance=1.1)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.title(\"Distribution of Subclusters as a Percentage of Total\")\n",
    "plt.show()\n",
    "\n",
    "# Subcluster breakdown within each cluster\n",
    "for cluster in cluster_counts.index:\n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "    subcluster_counts = cluster_data['subcluster'].value_counts().sort_index()\n",
    "    print(f\"Subclusters for Cluster {cluster}:\")\n",
    "    for subcluster, subcount in subcluster_counts.items():\n",
    "        subpercentage = (subcount / total_subcluster_occurrences) * 100\n",
    "        print(f\"  Subcluster {subcluster}: {subcount} occurrences ({subpercentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64b14e",
   "metadata": {},
   "source": [
    "#### Most Common Genre in each Cluster/Subcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c08709",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_top_genres = audio_features_kmeans_df.groupby('cluster')['genre'].apply(lambda x: Counter(x).most_common(5))\n",
    "\n",
    "for cluster, top_genres in cluster_top_genres.items():\n",
    "    print(f\"Cluster {cluster}: Top 5 Genres - {', '.join([genre for genre, _ in top_genres])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_subgroup_genre_counts = audio_features_kmeans_df.groupby(['cluster', 'subcluster'])['genre'].apply(lambda x: [genre for genre, count in Counter(x).most_common(5)])\n",
    "\n",
    "for (genre_cluster), top_genres in cluster_subgroup_genre_counts.items():\n",
    "    top_genres_str = \", \".join(top_genres)\n",
    "    print(f\"Subcluster {genre_cluster}: Top 5 Genres - {top_genres_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9628d",
   "metadata": {},
   "source": [
    "### Cluster/Subcluster Prediction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_track = [{'id': '4OAuvHryIVv4kMDNSLuPt6', 'danceability': 0.516, 'energy': 0.777, 'key': 1, 'loudness': -4.908, 'speechiness': 0.0375, 'acousticness': 0.00108, 'instrumentalness': 1.62e-06, 'liveness': 0.0761, 'valence': 0.408, 'tempo': 125.047, 'duration_ms': 223093}]\n",
    "\n",
    "audio_features = sample_track[0]\n",
    "sample_track_audio_features = [\n",
    "    audio_features['danceability'],\n",
    "    audio_features['energy'],\n",
    "    audio_features['loudness'],\n",
    "    audio_features['speechiness'],\n",
    "    audio_features['acousticness'],\n",
    "    audio_features['liveness'],\n",
    "    audio_features['valence'],\n",
    "    audio_features['tempo'],\n",
    "]\n",
    "\n",
    "# Reshape the audio feature vector to match the input format\n",
    "sample_track_audio_features = [sample_track_audio_features]\n",
    "\n",
    "# Predict the cluster and subcluster for the sample track's audio features\n",
    "predicted_cluster = kmeans_main_model.predict(sample_track_audio_features)\n",
    "kmeans_subcluster_model = subcluster_models[predicted_cluster[0]]\n",
    "predicted_subcluster = kmeans_subcluster_model.predict(sample_track_audio_features)  # Use the appropriate subcluster model\n",
    "\n",
    "print(f\"Sample track belongs to Cluster {predicted_cluster[0]}, Subcluster {predicted_subcluster[0]}\")\n",
    "# print(f\"Sample track belongs to Cluster {predicted_cluster[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392edb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
