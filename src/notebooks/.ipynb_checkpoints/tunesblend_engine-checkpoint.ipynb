{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ef8ae6-a054-4a64-9c97-4b373bb8130f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\"Libraries to help with jupyter notebook usage\"\n",
    "# Increases jupyter notebook display width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import Image # Helps display images in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b348ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\"Appends both parent and grandparent dir to current path, to allow importing\"\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "from jupyternotebook_utils import *\n",
    "from utils import *\n",
    "from data_processing import *\n",
    "from spotify_data import *\n",
    "from spotify_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1982b9d",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "Import files containing information regarding tracks from over 6000 different genres and their audio features, roughly 50 tracks per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca4218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_by_genre_file_path = f'../../data/processed_data/genres/audio_features_by_genre.csv'\n",
    "audio_features_by_genre_df = pd.read_csv(audio_features_by_genre_file_path)\n",
    "original_audio_features_by_genre_df = audio_features_by_genre_df.copy()\n",
    "\n",
    "clustered_audio_features_by_genre_file_path = f'../../data/processed_data/genres/audio_features_by_genre.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f6d68",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing\n",
    "1. Remove irrelevant columns such as key and duration\n",
    "2. Remove outliers for each audio features in `audio_features_df`\n",
    "3. Perform One-Hot-Encoding (OHE) for `track_popularity` and `release_date` in `track_details_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382570d5",
   "metadata": {},
   "source": [
    "## Utility for Pre-processing\n",
    "Declaration of constants and functions to be used for data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc264b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_graph_audio_features_df = audio_features_by_genre_df.copy()\n",
    "after_graph_audio_features_df = audio_features_by_genre_df.copy()\n",
    "\n",
    "num_bins = 250\n",
    "\n",
    "graph_height = 4\n",
    "graph_width = 4\n",
    "\n",
    "audio_features_list = ['danceability', 'energy', 'key', 'loudness', 'speechiness', \n",
    "                       'acousticness', 'instrumentalness', 'liveness', 'valence',\n",
    "                       'tempo', 'duration_ms']\n",
    "\n",
    "def plot_graph(plot_title, graph_height, graph_width, graph_features_list = audio_features_list, graph_df = before_graph_audio_features_df):\n",
    "    graph_height = graph_height\n",
    "    graph_width = graph_width\n",
    "    graph_count = len(graph_features_list)\n",
    "\n",
    "    fig, axes = plt.subplots(1, graph_count, figsize=(graph_width * graph_count, graph_height))\n",
    "    fig.suptitle(plot_title, fontsize=16)\n",
    "    \n",
    "    for i, audio_feature in enumerate(graph_features_list, start = 0):\n",
    "        ax = axes[i]\n",
    "        ax.hist(graph_df[audio_feature], bins=num_bins, range=(0, 1), edgecolor='none')\n",
    "        ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "        ax.set_xlabel(f'{audio_feature.capitalize()}')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_graph_audio_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe88e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Min-max normalization for selected features\n",
    "input_data_ranges = {\n",
    "    'loudness': (-60, 0),\n",
    "    'tempo': (0, 250),\n",
    "    'key': (-1, 11)\n",
    "}\n",
    "for feature, (feature_min, feature_max) in input_data_ranges.items():\n",
    "    after_graph_audio_features_df[feature] = (after_graph_audio_features_df[feature] - feature_min) / (feature_max - feature_min)\n",
    "\n",
    "# Step 2: Keep selected audio features\n",
    "selected_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence', 'tempo']\n",
    "filtered_data = after_graph_audio_features_df[selected_features].copy()\n",
    "\n",
    "# Step 3: Cube root transformation for selected features\n",
    "cubed_features = ['speechiness', 'acousticness', 'liveness']\n",
    "for feature in cubed_features:\n",
    "    filtered_data[feature] = np.cbrt(filtered_data[feature])\n",
    "\n",
    "# Step 4: Logarithmic transformation for selected features\n",
    "log_features = ['energy', 'loudness']\n",
    "for feature in log_features:\n",
    "    filtered_data[feature] = np.log1p(filtered_data[feature])\n",
    "\n",
    "# Step 5: IQR-filtering based on thresholds\n",
    "lower_thresholds =  {'danceability': 0.16850000000000004, 'energy': 0.14936944969853527, 'loudness': 0.5734535346157168, \n",
    "                     'speechiness': 0.11183139278235099, 'acousticness': -0.35285124201451823, 'liveness': 0.20276263879283324, \n",
    "                     'valence': -0.24249999999999988, 'tempo': 0.16009000000000007}\n",
    "upper_thresholds = {'danceability': 1.0525, 'energy': 0.8605850164229211, 'loudness': 0.698995265917933, \n",
    "                    'speechiness': 0.6924946680943335, 'acousticness': 1.280417950271011, 'liveness': 0.8754111662234604, \n",
    "                    'valence': 1.2494999999999998, 'tempo': 0.7998179999999999}\n",
    "\n",
    "for feature in selected_features:\n",
    "    filtered_data[feature] = np.where(\n",
    "        (filtered_data[feature] >= lower_thresholds[feature]) &\n",
    "        (filtered_data[feature] <= upper_thresholds[feature]),\n",
    "        filtered_data[feature],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "# Step 6: Min-max Normalization\n",
    "feature_min = {'danceability': 0.169, 'energy': 0.1501426584297195, 'loudness': 0.5734623376139655, \n",
    "               'speechiness': 0.27977873676275317, 'acousticness': 0.0, 'liveness': 0.21074564860592623, \n",
    "               'valence': 0.0, 'tempo': 0.164644}\n",
    "\n",
    "feature_max = {'danceability': 0.991, 'energy': 0.6931471805599453, 'loudness': 0.6983917371326527, \n",
    "               'speechiness': 0.692435557262704, 'acousticness': 0.9986648849277057, 'liveness': 0.8750340122833274, \n",
    "               'valence': 1.0, 'tempo': 0.799812}\n",
    "\n",
    "for feature in selected_features:\n",
    "    if feature in feature_min:\n",
    "        after_graph_audio_features_df[feature] = (after_graph_audio_features_df[feature] - feature_min[feature]) / (feature_max[feature] - feature_min[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77ef14",
   "metadata": {},
   "source": [
    "## Genre Clustering Using KMeans Algorithm\n",
    "\n",
    "Here's an overview of the whole clustering process:\n",
    "1. Identifying the optimal value of K for the Partitioning Clustering using the Elbow Method.\n",
    "2. Run Kmeans algorithm using the optimal K value.\n",
    "3. For each cluster, re-run Elbow Method to find the optimal K value for Hierachial Subclustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8cec1d",
   "metadata": {},
   "source": [
    "### Constant Declarations for KMeans Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output # clears output for better logging\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter # used to count frequency of genres in each cluster\n",
    "\n",
    "min_clusters = 1\n",
    "max_clusters = 11\n",
    "\n",
    "# NOTE: key, and duration_ms is removed\n",
    "audio_feature_columns = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = audio_features_by_genre_df.loc[:, audio_feature_columns]\n",
    "inertia_values = []\n",
    "\n",
    "for k in range(min_clusters, max_clusters):\n",
    "    \n",
    "    status = f'Attempting Cluster Size: {k}'\n",
    "    print(status, end='\\r')  # '\\r' moves the cursor to the beginning of the same line, effectively overwriting previous line\n",
    "    \n",
    "    kmeans_main_model = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans_main_model.fit(X)\n",
    "    inertia_values.append(kmeans_main_model.inertia_)\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(min_clusters, max_clusters), inertia_values, marker='o')\n",
    "plt.title('Determining Optimal Value for K')\n",
    "plt.xlabel('Number of Clusters, K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(range(min_clusters, max_clusters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_kmeans_df = audio_features_by_genre_df.copy()\n",
    "\n",
    "X = audio_features_kmeans_df.loc[:, audio_feature_columns]\n",
    "\n",
    "num_clusters = 6\n",
    "kmeans_main_model = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans_main_model.fit(X)\n",
    "\n",
    "model_file_path = '../models/modlkmeans_model.joblib'\n",
    "joblib.dump(kmeans_main_model, model_file_path)\n",
    "\n",
    "print(f'KMeans model saved to {model_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150746ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = '../models/modlkmeans_model.joblib'\n",
    "kmeans_main_model = joblib.load(model_file_path)\n",
    "\n",
    "status = f'Kmeans Model succesfully loaded'\n",
    "print(status, end='\\r')\n",
    "\n",
    "audio_features_kmeans_df['cluster'] = kmeans_main_model.labels_ + 1\n",
    "audio_features_kmeans_df.sort_values(by='cluster', inplace=True)\n",
    "\n",
    "selected_columns = ['genre', 'cluster', 'track_name', 'track_uri']\n",
    "selected_df = audio_features_kmeans_df[selected_columns]\n",
    "clustered_audio_features_by_genre_file_path = '../../data/processed_data/genres/clustered_audio_features_by_genre.csv'\n",
    "selected_df.to_csv(clustered_audio_features_by_genre_file_path, index=False)\n",
    "\n",
    "print(f'Sorted and selected data with cluster assignments written to {clustered_audio_features_by_genre_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154b722",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_clusters = audio_features_kmeans_df['cluster'].unique()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    status = f'Finding optimal value of K for Cluster {cluster}'\n",
    "    print(status)\n",
    "    \n",
    "    # Filter data for the current cluster\n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "    X = cluster_data.loc[:, audio_feature_columns]\n",
    "\n",
    "    # Perform the elbow method to find the optimal K value\n",
    "    inertia_values = []\n",
    "    \n",
    "    for k in range(min_clusters, max_clusters):\n",
    "        status = f'Attempting Cluster Size: {k}'\n",
    "        print(status, end='\\r')\n",
    "        \n",
    "        kmeans_subcluster_model = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans_subcluster_model.fit(X)\n",
    "        inertia_values.append(kmeans_subcluster_model.inertia_)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Plot the elbow method results for each cluster on the same chart\n",
    "    plt.plot(range(min_clusters, max_clusters), inertia_values, marker='o', label=f'Cluster {cluster}')\n",
    "    plt.title('Elbow Method for Optimal K')\n",
    "    plt.xlabel('Number of Clusters (K)')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.xticks(range(min_clusters, max_clusters))\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subclusters_per_cluster = {\n",
    "    1: 6,\n",
    "    2: 5,\n",
    "    3: 6,\n",
    "    4: 6,\n",
    "    5: 5,\n",
    "    6: 5\n",
    "}\n",
    "\n",
    "for cluster, num_subclusters in num_subclusters_per_cluster.items():\n",
    "    status = f'Building Subcluster Model for Cluster {cluster}'\n",
    "    print(status, end='\\r')\n",
    "    \n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "\n",
    "    X_subcluster = cluster_data.loc[:, audio_feature_columns]\n",
    "\n",
    "    kmeans_subcluster_model = KMeans(n_clusters=num_subclusters, random_state=42)\n",
    "    kmeans_subcluster_model.fit(X_subcluster)\n",
    "\n",
    "    # Save the subcluster KMeans model\n",
    "    subcluster_model_file_path = f'../models/subcluster_kmeans_model_cluster_{cluster}.joblib'\n",
    "    joblib.dump(kmeans_subcluster_model, subcluster_model_file_path)\n",
    "\n",
    "print(\"All subclustering models successfully built and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91701f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcluster_models = {}\n",
    "\n",
    "# Loading subcluster models into subcluster_models\n",
    "for cluster in num_subclusters_per_cluster.keys():\n",
    "    subcluster_model_file_path = f'../models/subcluster_kmeans_model_cluster_{cluster}.joblib'\n",
    "    loaded_subcluster_model = joblib.load(subcluster_model_file_path)\n",
    "    subcluster_models[cluster] = loaded_subcluster_model\n",
    "    \n",
    "status = f'All Subcluster Models succesfully loaded'\n",
    "print(status, end='\\r')\n",
    "\n",
    "# Assigning subcluster labels to data\n",
    "for cluster, kmeans_subcluster_model in subcluster_models.items():\n",
    "    status = f'Processing Subclustering for Cluster {cluster}'\n",
    "    print(status, end='\\r')\n",
    "    \n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "    X_subcluster = cluster_data.loc[:, audio_feature_columns]\n",
    "    subcluster_labels = kmeans_subcluster_model.predict(X_subcluster)\n",
    "    audio_features_kmeans_df.loc[audio_features_kmeans_df['cluster'] == cluster, 'subcluster'] = subcluster_labels.astype(int) + 1\n",
    "\n",
    "audio_features_kmeans_df.sort_values(by=['cluster', 'subcluster'], inplace=True)\n",
    "\n",
    "selected_columns = ['genre', 'cluster', 'subcluster', 'track_name', 'track_uri']\n",
    "clustered_audio_features_by_genre_file_path = '../../data/processed_data/genres/clustered_audio_features_by_genre.csv'\n",
    "audio_features_kmeans_df[selected_columns].to_csv(clustered_audio_features_by_genre_file_path, index=False)\n",
    "\n",
    "print(\"All subclustering processes completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d175405",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_kmeans_df = pd.read_csv(clustered_audio_features_by_genre_file_path)\n",
    "\n",
    "# Convert cluster and subcluster columns to integers and then combine them as strings\n",
    "audio_features_kmeans_df['genre_cluster'] = (\n",
    "    audio_features_kmeans_df['cluster'].astype(int).astype(str) +\n",
    "    ', ' +\n",
    "    audio_features_kmeans_df['subcluster'].astype(int).astype(str)\n",
    ")\n",
    "\n",
    "audio_features_kmeans_df.to_csv(clustered_audio_features_by_genre_file_path, index=False)\n",
    "\n",
    "print(\"Added 'genre_cluster' column and saved to CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98fe10",
   "metadata": {},
   "source": [
    "### Breakdown of Cluster Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69664a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_counts = audio_features_kmeans_df['cluster'].value_counts().sort_index()\n",
    "sizes = cluster_counts.values\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, autopct='', startangle=140)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.title(\"Distribution of Occurrences across Clusters\")\n",
    "plt.legend(labels=[f\"Cluster {cluster}\" for cluster in cluster_counts.index], loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "total_occurrences = len(audio_features_kmeans_df)\n",
    "\n",
    "cluster_counts = audio_features_kmeans_df['cluster'].value_counts().sort_index()\n",
    "for cluster, count in cluster_counts.items():\n",
    "    percentage = (count / total_occurrences) * 100\n",
    "    print(f\"Cluster {cluster}: {count} occurrences ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d76182",
   "metadata": {},
   "source": [
    "### Breakdown of Sub-cluster Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786029c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subcluster_counts = audio_features_kmeans_df['genre_cluster'].value_counts().sort_index()\n",
    "total_subcluster_occurrences = len(audio_features_kmeans_df)\n",
    "subcluster_percentages = (subcluster_counts / total_subcluster_occurrences) * 100\n",
    "\n",
    "# Create a pie chart for subcluster distribution\n",
    "subcluster_labels = [f\"({subcluster})\" for subcluster in subcluster_counts.index]\n",
    "subcluster_sizes = subcluster_percentages.values\n",
    "\n",
    "plt.figure(figsize=(8, 8))  # Adjust the figure size if needed\n",
    "\n",
    "# Use the labeldistance parameter to control the label positions\n",
    "plt.pie(subcluster_sizes, labels=subcluster_labels, autopct='', startangle=140, labeldistance=1.1)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.title(\"Distribution of Subclusters as a Percentage of Total\")\n",
    "plt.show()\n",
    "\n",
    "# Subcluster breakdown within each cluster\n",
    "for cluster in cluster_counts.index:\n",
    "    cluster_data = audio_features_kmeans_df[audio_features_kmeans_df['cluster'] == cluster]\n",
    "    subcluster_counts = cluster_data['subcluster'].value_counts().sort_index()\n",
    "    print(f\"Subclusters for Cluster {cluster}:\")\n",
    "    for subcluster, subcount in subcluster_counts.items():\n",
    "        subpercentage = (subcount / total_subcluster_occurrences) * 100\n",
    "        print(f\"  Subcluster {subcluster}: {subcount} occurrences ({subpercentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64b14e",
   "metadata": {},
   "source": [
    "#### Most Common Genre in each Cluster/Subcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c08709",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_top_genres = audio_features_kmeans_df.groupby('cluster')['genre'].apply(lambda x: Counter(x).most_common(5))\n",
    "\n",
    "for cluster, top_genres in cluster_top_genres.items():\n",
    "    print(f\"Cluster {cluster}: Top 5 Genres - {', '.join([genre for genre, _ in top_genres])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_subgroup_genre_counts = audio_features_kmeans_df.groupby(['cluster', 'subcluster'])['genre'].apply(lambda x: [genre for genre, count in Counter(x).most_common(5)])\n",
    "\n",
    "for (genre_cluster), top_genres in cluster_subgroup_genre_counts.items():\n",
    "    top_genres_str = \", \".join(top_genres)\n",
    "    print(f\"Subcluster {genre_cluster}: Top 5 Genres - {top_genres_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9628d",
   "metadata": {},
   "source": [
    "### Cluster/Subcluster Prediction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe02eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans Model succesfully loaded\r",
      "All Subcluster Models succesfully loaded\r"
     ]
    }
   ],
   "source": [
    "model_file_path = '../models/modlkmeans_model.joblib'\n",
    "kmeans_main_model = joblib.load(model_file_path)\n",
    "\n",
    "status = f'Kmeans Model succesfully loaded'\n",
    "print(status, end='\\r')\n",
    "\n",
    "subcluster_models = {}\n",
    "\n",
    "num_subclusters_per_cluster = {\n",
    "    1: 6,\n",
    "    2: 5,\n",
    "    3: 6,\n",
    "    4: 6,\n",
    "    5: 5,\n",
    "    6: 5\n",
    "}\n",
    "\n",
    "# Loading subcluster models into subcluster_models\n",
    "for cluster in num_subclusters_per_cluster.keys():\n",
    "    subcluster_model_file_path = f'../models/subcluster_kmeans_model_cluster_{cluster}.joblib'\n",
    "    loaded_subcluster_model = joblib.load(subcluster_model_file_path)\n",
    "    subcluster_models[cluster] = loaded_subcluster_model\n",
    "    \n",
    "status = f'All Subcluster Models succesfully loaded'\n",
    "print(status, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f37812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample track belongs to Cluster 6, Subcluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample_track = [{'id': '3Qaw8WaLG0iPXfwVS4cQ11', 'danceability': 0.311, 'energy': 0.311, 'key': 5, 'loudness': -11.516, 'speechiness': 0.0323, 'acousticness': 0.69, 'instrumentalness': 0, 'liveness': 0.195, 'valence': 0.369, 'tempo': 76.951, 'duration_ms': 239507}]\n",
    "\n",
    "audio_features = sample_track[0]\n",
    "sample_track_audio_features = [\n",
    "    audio_features['danceability'],\n",
    "    audio_features['energy'],\n",
    "    audio_features['loudness'],\n",
    "    audio_features['speechiness'],\n",
    "    audio_features['acousticness'],\n",
    "    audio_features['liveness'],\n",
    "    audio_features['valence'],\n",
    "    audio_features['tempo'],\n",
    "]\n",
    "# sample_track_audio_features = [0.5269, 0.4648, -8.3644, 0.039, 0.5454, 0.1439, 0.3232, 126.9117]\n",
    "\n",
    "# Reshape the audio feature vector to match the input format\n",
    "sample_track_audio_features = [sample_track_audio_features]\n",
    "\n",
    "# Predict the cluster and subcluster for the sample track's audio features\n",
    "predicted_cluster = kmeans_main_model.predict(sample_track_audio_features) + 1\n",
    "kmeans_subcluster_model = subcluster_models[predicted_cluster[0]]\n",
    "predicted_subcluster = kmeans_subcluster_model.predict(sample_track_audio_features) + 1  # Use the appropriate subcluster model\n",
    "\n",
    "print(f\"Sample track belongs to Cluster {predicted_cluster[0]}, Subcluster {predicted_subcluster[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
