{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef8ae6-a054-4a64-9c97-4b373bb8130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\"Libraries to help with data processing\"\n",
    "from scipy import stats\n",
    "\n",
    "\"Libraries to help with jupyter notebook usage\"\n",
    "# Increases jupyter notebook display width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import Image # Helps display images in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\"Appends both parent and grandparent dir to current path, to allow importing\"\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "from jupyternotebook_utils import *\n",
    "from utils import *\n",
    "from data_processing import *\n",
    "from spotify_data import *\n",
    "from spotify_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1982b9d",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "Import files containing information regarding tracks from over 10,000 playlists in terms of audio featuers and various details such as global popularity and release date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_df = []\n",
    "track_details_df = []\n",
    "\n",
    "for i in range(10):\n",
    "    audio_features_file_path = f'../../data/processed_data/audio_features/audio_features-{i*1000}-{(i+1)*1000 - 1}.csv'\n",
    "    df = pd.read_csv(audio_features_file_path)\n",
    "    audio_features_df.append(df)\n",
    "    \n",
    "    track_details_file_path = f'../../data/processed_data/playlist_details/details-{i*1000}-{(i+1)*1000 - 1}.csv'\n",
    "    df = pd.read_csv(track_details_file_path)\n",
    "    track_details_df.append(df)\n",
    "\n",
    "audio_features_df = pd.concat(audio_features_df, ignore_index=True)\n",
    "track_details_df = pd.concat(track_details_df, ignore_index=True)\n",
    "\n",
    "original_track_details_df = track_details_df.copy()\n",
    "original_audio_features_df = audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ee26f",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "1. Perform min-max normalisation on audio features with custom ranges\n",
    "2. Remove irrelevant columns\n",
    "3. Various Normalization Techniques\n",
    "4. Standard Normalization\n",
    "5. Perform One-Hot-Encoding (OHE) for `track_popularity` and `release_date` in `track_details_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e30fa",
   "metadata": {},
   "source": [
    "### Data Processing Utilities\n",
    "Constants and Functions that will be used for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_graph_audio_features_df = audio_features_df.copy()\n",
    "after_graph_audio_features_df = audio_features_df.copy()\n",
    "original_graph_audio_features_df = audio_features_df.copy()\n",
    "\n",
    "num_bins = 250\n",
    "\n",
    "graph_height = 4\n",
    "graph_width = 4\n",
    "\n",
    "audio_features_list = ['danceability', 'energy', 'key', 'loudness', 'speechiness', \n",
    "                       'acousticness', 'instrumentalness', 'liveness', 'valence',\n",
    "                       'tempo', 'duration_ms']\n",
    "\n",
    "def plot_graph(plot_title, subplots_per_row, graph_features_list=audio_features_list, max_x=1, graph_df=after_graph_audio_features_df):\n",
    "    num_features = len(graph_features_list)\n",
    "    num_rows = (num_features + subplots_per_row - 1) // subplots_per_row\n",
    "    total_subplots = num_rows * subplots_per_row\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=subplots_per_row, figsize=(25, 6 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, audio_feature in enumerate(graph_features_list):\n",
    "            ax = axes[i]\n",
    "            ax.hist(graph_df[audio_feature], bins=num_bins, range=(0, max_x), edgecolor='none')\n",
    "            ax.set_title(f'{str(audio_feature).capitalize()}')\n",
    "            ax.set_xlabel(f'{audio_feature.capitalize()}')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_xlim(0, max_x)\n",
    "            \n",
    "    # Hide extra subplots\n",
    "    for i in range(num_features, total_subplots):\n",
    "        axes[i].set_visible(False)\n",
    "            \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0a3cb",
   "metadata": {},
   "source": [
    "### Initial Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_title = 'Initial Frequency Histogram of Raw Dataset'\n",
    "\n",
    "plot_graph(graph_title, subplots_per_row=4, max_x=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e01d76",
   "metadata": {},
   "source": [
    "### 1. Min-max Normalization\n",
    "To ensure equal weighting of audio features when building up the playlist vector, we can scale all audio features to a common scale, namely [0, 1]. After some research on the Spotify API documentation, there are 3 audio features with ranges outside of [0, 1], such as:\n",
    "\n",
    "    - Loudness: [-60, 0]\n",
    "    - Tempo: [0, 250]\n",
    "    - Key: [-1, 11]\n",
    "\n",
    "We can perform Min-Max normalization to set up the data for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_ranges = {\n",
    "    'loudness': (-60, 0),\n",
    "    'tempo': (0, 250),\n",
    "    'key': (-1, 11)\n",
    "}\n",
    "\n",
    "# min-max normalization\n",
    "for column, (input_min, input_max) in input_data_ranges.items():\n",
    "    after_graph_audio_features_df[column] = (before_graph_audio_features_df[column] - input_min) / (input_max - input_min)\n",
    "\n",
    "plot_graph(plot_title='After Min-max Normalization', subplots_per_row=3, max_x=1, graph_features_list=['loudness', 'tempo', 'key'])\n",
    "\n",
    "before_graph_audio_features_df = after_graph_audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0938b",
   "metadata": {},
   "source": [
    "### 2. Removing Irrelevant Columns\n",
    "\n",
    "While analyzing the audio features for building our recommendation system, it became evident that certain columns don't contribute significantly to the process. Specifically, the `key` and `duration_ms` columns fall into this category. Allow me to explain:\n",
    "- `key`: the musical key of a track, doesn't provide substantial insights relevant to our recommendation system's objectives. \n",
    "- `duration_ms`: the length of a track doesn't really hold the significance needed to recommend songs effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_list = ['danceability', 'energy', 'loudness', 'speechiness', 'instrumentalness','acousticness', 'liveness', 'valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d7ff7",
   "metadata": {},
   "source": [
    "Another thing that can be observed is the incompleteness of data for a track's `instrumentalness`. Almost half of the data is 0, with the 75th percentile being less than 0.001 as well. Hence it will be removed from the analysis as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac371ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_rows_count =  (after_graph_audio_features_df['instrumentalness'] == 0).sum()\n",
    "print(f\"Rows with 0 for 'instrumentalness': {zero_rows_count}, ({round(zero_rows_count * 100 / len(after_graph_audio_features_df), 1)}%)\")\n",
    "\n",
    "after_graph_audio_features_df['instrumentalness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79671d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "plot_title = 'Updated Frequency Histogram'\n",
    "plot_graph(plot_title, subplots_per_row=4, graph_features_list=audio_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308a8f6",
   "metadata": {},
   "source": [
    "### 3. Fix Left/Right-skewed Data\n",
    "For right-skewed data, we will be using cube-root-transformation to attempt to normalize the data.\n",
    "For left-skewed data, we will be using exponential-transformation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the skewed columns\n",
    "right_skewed_columns = ['speechiness', 'acousticness', 'liveness']\n",
    "left_skewed_columns = ['energy', 'loudness']\n",
    "\n",
    "# Apply transformations for both left and right skewed columns\n",
    "for column in right_skewed_columns + left_skewed_columns:\n",
    "    \n",
    "    # Perform cube-root/logarithmic transformation to normalize dataset\n",
    "    if column in right_skewed_columns:\n",
    "        # Apply cube root transformation\n",
    "        after_graph_audio_features_df.loc[:, column] = np.cbrt(before_graph_audio_features_df[column])\n",
    "    elif column in left_skewed_columns:\n",
    "        # Apply logarithmic transformation\n",
    "        after_graph_audio_features_df.loc[:, column] = np.log1p(before_graph_audio_features_df[column].abs())\n",
    "\n",
    "plot_title_right = 'Updated Right-skewed Columns with Cube Root Transformation'\n",
    "plot_title_left = 'Updated Left-skewed Columns with Logarithmic Transformation'\n",
    "plot_graph(plot_title_right, subplots_per_row=3, graph_features_list=right_skewed_columns, graph_df=after_graph_audio_features_df)\n",
    "plot_graph(plot_title_left, subplots_per_row=2, graph_features_list=left_skewed_columns, graph_df=after_graph_audio_features_df)\n",
    "\n",
    "before_graph_audio_features_df = after_graph_audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698f490",
   "metadata": {},
   "source": [
    "### 4. Standard Normalization\n",
    "Perform IQR-based outlier filtering and min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_thresholds = {}\n",
    "upper_thresholds = {}\n",
    "feature_min = {}\n",
    "feature_max = {}\n",
    "\n",
    "for column in audio_features_list:\n",
    "    \n",
    "    Q1 = after_graph_audio_features_df[column].quantile(0.25)\n",
    "    Q3 = after_graph_audio_features_df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Perform IQR-based outlier filtering    \n",
    "    lower_threshold = Q1 - 1.5 * IQR\n",
    "    upper_threshold = Q3 + 1.5 * IQR\n",
    "    temp_after_graph_audio_features_df = after_graph_audio_features_df.copy()\n",
    "    after_graph_audio_features_df = temp_after_graph_audio_features_df[\n",
    "        (temp_after_graph_audio_features_df[column] > lower_threshold) &\n",
    "        (temp_after_graph_audio_features_df[column] < upper_threshold)\n",
    "    ]\n",
    "    \n",
    "    lower_thresholds[column] = Q1 - 1.5 * IQR\n",
    "    upper_thresholds[column] = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Store min-max parameters for left-skewed columns\n",
    "    column_min = after_graph_audio_features_df[column].min()\n",
    "    column_max = after_graph_audio_features_df[column].max()\n",
    "    \n",
    "    feature_min[column] = column_min\n",
    "    feature_max[column] = column_max\n",
    "    \n",
    "    after_graph_audio_features_df.loc[:, column] = (after_graph_audio_features_df[column] - column_min) / (column_max - column_min)\n",
    "\n",
    "plot_title = 'Frequency Histogram for Processed Data'\n",
    "plot_graph(plot_title, subplots_per_row=2, graph_features_list=audio_features_list, graph_df=after_graph_audio_features_df)\n",
    "\n",
    "print(\"lower_thresholds = \")\n",
    "print(lower_thresholds)\n",
    "\n",
    "print(\"\\nupper_thresholds = \")\n",
    "print(upper_thresholds)\n",
    "\n",
    "print('\\nfeature_min = ')\n",
    "print(feature_min)\n",
    "\n",
    "print('\\nfeature_max = ')\n",
    "print(feature_max)\n",
    "\n",
    "before_graph_audio_features_df = after_graph_audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_df = after_graph_audio_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605af4f",
   "metadata": {},
   "source": [
    "## Correlation Matrix\n",
    "Overview of the correlation between audio features (note: correlation need not necessarily imply causation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adda922-c455-4d97-8686-bfb2625e884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = audio_features_df[audio_features_list].corr()\n",
    "\n",
    "# Create a mask to hide the lower triangle (including the diagonal)\n",
    "mask = np.tril(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Plotting the correlation matrix as a heatmap, showing only the values in the upper triangle\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", center=0, mask=~mask)\n",
    "plt.title(\"Correlation Matrix of Audio Features\")\n",
    "plt.savefig(f\"../../resources/audio_feature_plots/correlation.png\", format=\"png\", dpi=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = audio_features_df.merge(track_details_df, on='id', how='inner')\n",
    "\n",
    "tracks_with_missing_details = merged_df.loc[merged_df['track_uri'].isna(), 'id']\n",
    "\n",
    "merged_df = merged_df.drop(index=merged_df[merged_df['id'].isin(tracks_with_missing_details)].index)\n",
    "original_merged_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624485d",
   "metadata": {},
   "source": [
    "## Audio Feature Trend Over the Years\n",
    "Here's how the audio_features change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1f49f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trend_analysis_df = original_merged_df.copy()\n",
    "\n",
    "trend_analysis_df = trend_analysis_df.dropna(subset=['release_date'])\n",
    "selected_columns = ['danceability', 'energy', 'loudness', 'tempo', 'speechiness', 'acousticness', 'liveness', 'valence', 'release_date']\n",
    "trend_analysis_df = trend_analysis_df[selected_columns]\n",
    "\n",
    "trend_analysis_df['release_date'] = pd.to_datetime(trend_analysis_df['release_date'], errors='coerce')\n",
    "\n",
    "trend_analysis_df['release_year'] = trend_analysis_df['release_date'].dt.to_period('Q').astype(str)\n",
    "trend_analysis_df['release_year'] = trend_analysis_df['release_year'].apply(lambda x: x.replace('Q1', 'H1').replace('Q2', 'H1').replace('Q3', 'H2').replace('Q4', 'H2'))\n",
    "\n",
    "trend_analysis_df = trend_analysis_df.groupby('release_year').mean().reset_index()\n",
    "\n",
    "subplots_per_row = 2\n",
    "num_rows = len(audio_features_list) // subplots_per_row + (len(audio_features_list) % subplots_per_row > 0)\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=subplots_per_row, figsize=(25, 6 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, audio_feature in enumerate(audio_features_list):\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.plot(trend_analysis_df.index, trend_analysis_df[audio_feature], label=audio_feature)\n",
    "    \n",
    "    ax.set_title(f'{audio_feature.capitalize()} Over The Years')\n",
    "    ax.grid(True)\n",
    "\n",
    "#     # x_ticks: how often a label is drawn, x_labels: what the label is\n",
    "#     x_ticks = trend_analysis_df.index[::120]\n",
    "#     x_labels = [date.split(\"-\")[0] for date in trend_analysis_df['release_year_month'][::120]]\n",
    "#     ax.set_xticks(x_ticks)\n",
    "#     ax.set_xticklabels(x_labels, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7d4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
